{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import math\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8571</td>\n",
       "      <td>18506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8571</td>\n",
       "      <td>33644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8571</td>\n",
       "      <td>32627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5725</td>\n",
       "      <td>14855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5725</td>\n",
       "      <td>28037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85817</th>\n",
       "      <td>21913</td>\n",
       "      <td>21835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85818</th>\n",
       "      <td>21913</td>\n",
       "      <td>37137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85819</th>\n",
       "      <td>21913</td>\n",
       "      <td>41653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85820</th>\n",
       "      <td>21913</td>\n",
       "      <td>1682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85821</th>\n",
       "      <td>21913</td>\n",
       "      <td>6939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemset   item\n",
       "0         8571  18506\n",
       "1         8571  33644\n",
       "2         8571  32627\n",
       "3         5725  14855\n",
       "4         5725  28037\n",
       "...        ...    ...\n",
       "85817    21913  21835\n",
       "85818    21913  37137\n",
       "85819    21913  41653\n",
       "85820    21913   1682\n",
       "85821    21913   6939\n",
       "\n",
       "[85822 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemsetitem_trn = pd.read_csv(r'C:\\Users\\a3179\\OneDrive\\바탕 화면\\datamining_termproject\\dataset\\itemset_item_training.csv', names = ['itemset', 'item'])\n",
    "itemsetitem_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemset</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8571</td>\n",
       "      <td>18506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8571</td>\n",
       "      <td>33644</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8571</td>\n",
       "      <td>32627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5725</td>\n",
       "      <td>14855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5725</td>\n",
       "      <td>28037</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85817</th>\n",
       "      <td>21913</td>\n",
       "      <td>21835</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85818</th>\n",
       "      <td>21913</td>\n",
       "      <td>37137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85819</th>\n",
       "      <td>21913</td>\n",
       "      <td>41653</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85820</th>\n",
       "      <td>21913</td>\n",
       "      <td>1682</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85821</th>\n",
       "      <td>21913</td>\n",
       "      <td>6939</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85822 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       itemset   item  rating\n",
       "0         8571  18506       1\n",
       "1         8571  33644       1\n",
       "2         8571  32627       1\n",
       "3         5725  14855       1\n",
       "4         5725  28037       1\n",
       "...        ...    ...     ...\n",
       "85817    21913  21835       1\n",
       "85818    21913  37137       1\n",
       "85819    21913  41653       1\n",
       "85820    21913   1682       1\n",
       "85821    21913   6939       1\n",
       "\n",
       "[85822 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = pd.DataFrame({'rating': [1 for i in range(len(itemsetitem_trn))]})\n",
    "itemsetitem_rating = pd.concat([itemsetitem_trn, rating], axis=1)\n",
    "itemsetitem_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42553</th>\n",
       "      <th>42554</th>\n",
       "      <th>42555</th>\n",
       "      <th>42556</th>\n",
       "      <th>42557</th>\n",
       "      <th>42558</th>\n",
       "      <th>42559</th>\n",
       "      <th>42560</th>\n",
       "      <th>42561</th>\n",
       "      <th>42562</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27688</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27689</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27690</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27691</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27693</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22156 rows × 42563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item     0      1      2      3      4      5      6      7      8      9      \\\n",
       "itemset                                                                         \n",
       "0          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "6          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "7          NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...        ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "27688      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27689      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27690      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27691      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27693      NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "item     ...  42553  42554  42555  42556  42557  42558  42559  42560  42561  \\\n",
       "itemset  ...                                                                  \n",
       "0        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "6        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "7        ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "27688    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27689    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27690    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27691    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "27693    ...    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "item     42562  \n",
       "itemset         \n",
       "0          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "6          NaN  \n",
       "7          NaN  \n",
       "...        ...  \n",
       "27688      NaN  \n",
       "27689      NaN  \n",
       "27690      NaN  \n",
       "27691      NaN  \n",
       "27693      NaN  \n",
       "\n",
       "[22156 rows x 42563 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_item_rating = itemsetitem_rating.pivot_table('rating', index='itemset', columns='item')\n",
    "itemset_item_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.42 GiB for an array with shape (26549, 42563) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inter_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros( (\u001b[39mlen\u001b[39;49m(itemsetitem_rating[\u001b[39m'\u001b[39;49m\u001b[39mitemset\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique()), \u001b[39mlen\u001b[39;49m(itemsetitem_rating[\u001b[39m'\u001b[39;49m\u001b[39mitem\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique())) )\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m item, itemset, rating \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m], itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m], itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     inter_mat[itemset][item] \u001b[39m=\u001b[39m rating\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.42 GiB for an array with shape (26549, 42563) and data type float64"
     ]
    }
   ],
   "source": [
    "inter_mat = np.zeros( (len(itemsetitem_rating['itemset'].unique()), len(itemsetitem_rating['item'].unique())) )\n",
    "for item, itemset, rating in zip(itemsetitem_rating['item'], itemsetitem_rating['itemset'], itemsetitem_rating['rating']):\n",
    "    inter_mat[itemset][item] = rating\n",
    "inter_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42553</th>\n",
       "      <th>42554</th>\n",
       "      <th>42555</th>\n",
       "      <th>42556</th>\n",
       "      <th>42557</th>\n",
       "      <th>42558</th>\n",
       "      <th>42559</th>\n",
       "      <th>42560</th>\n",
       "      <th>42561</th>\n",
       "      <th>42562</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itemset</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item     0      1      2      3      4      5      6      7      8      9      \\\n",
       "itemset                                                                         \n",
       "0          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "6          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7          0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "item     ...  42553  42554  42555  42556  42557  42558  42559  42560  42561  \\\n",
       "itemset  ...                                                                  \n",
       "0        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "6        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "7        ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "item     42562  \n",
       "itemset         \n",
       "0          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "6          0.0  \n",
       "7          0.0  \n",
       "\n",
       "[5 rows x 42563 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemset_item_rating.fillna(0, inplace = True)\n",
    "itemset_item_rating.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22156"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemset_item_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m melted_data \u001b[39m=\u001b[39m []\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m itemset_item_rating:\n\u001b[1;32m----> 4\u001b[0m     melted_chunk \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmelt(chunk)\n\u001b[0;32m      5\u001b[0m     melted_data\u001b[39m.\u001b[39mappend(melted_chunk)\n\u001b[0;32m      7\u001b[0m melted_data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\melt.py:50\u001b[0m, in \u001b[0;36mmelt\u001b[1;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mmelt\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcaller\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpd.melt(df, \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mother\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataFrame.melt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[0;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmelt\u001b[39m(\n\u001b[0;32m     40\u001b[0m     frame: DataFrame,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39m# If multiindex, gather names of columns on all level for checking presence\u001b[39;00m\n\u001b[0;32m     49\u001b[0m     \u001b[39m# of `id_vars` and `value_vars`\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(frame\u001b[39m.\u001b[39;49mcolumns, MultiIndex):\n\u001b[0;32m     51\u001b[0m         cols \u001b[39m=\u001b[39m [x \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m frame\u001b[39m.\u001b[39mcolumns \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m c]\n\u001b[0;32m     52\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "chunk_size = 100000  # 배치 크기 설정\n",
    "melted_data = []\n",
    "for chunk in itemset_item_rating:\n",
    "    melted_chunk = pd.melt(chunk)\n",
    "    melted_data.append(melted_chunk)\n",
    "\n",
    "melted_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42563"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itemsetitem_trn['item'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 54/42563 [2:22:26<1868:52:25, 158.27s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m itemset \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(itemsetitem_trn[\u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique())):\n\u001b[0;32m      3\u001b[0m         negative_sample \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries([item, itemset, \u001b[39m0\u001b[39m], index\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m         itemsetitem_rating \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([itemsetitem_rating, negative_sample\u001b[39m.\u001b[39;49mto_frame()\u001b[39m.\u001b[39;49mT], ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      6\u001b[0m itemsetitem_rating\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[0;32m    369\u001b[0m     objs,\n\u001b[0;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[0;32m    379\u001b[0m )\n\u001b[1;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[0;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    618\u001b[0m )\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[0;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\concat.py:223\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    217\u001b[0m vals \u001b[39m=\u001b[39m [ju\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mvalues \u001b[39mfor\u001b[39;00m ju \u001b[39min\u001b[39;00m join_units]\n\u001b[0;32m    219\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m blk\u001b[39m.\u001b[39mis_extension:\n\u001b[0;32m    220\u001b[0m     \u001b[39m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[39m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[39m#  than concat_compat\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mconcatenate(vals, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    224\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    225\u001b[0m     \u001b[39m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    226\u001b[0m     values \u001b[39m=\u001b[39m concat_compat(vals, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for item in tqdm(range(len(itemsetitem_trn['item'].unique()))):\n",
    "    for itemset in range(len(itemsetitem_trn['itemset'].unique())):\n",
    "        negative_sample = pd.Series([item, itemset, 0], index=['item', 'itemset', 'rating'])\n",
    "        itemsetitem_rating = pd.concat([itemsetitem_rating, negative_sample.to_frame().T], ignore_index=True)\n",
    "\n",
    "itemsetitem_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.03 GiB for an array with shape (943025828,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m unique_items \u001b[39m=\u001b[39m itemsetitem_trn[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      2\u001b[0m unique_itemsets \u001b[39m=\u001b[39m itemsetitem_trn[\u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m      4\u001b[0m negative_samples \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[1;32m----> 5\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m: unique_items\u001b[39m.\u001b[39;49mrepeat(\u001b[39mlen\u001b[39;49m(unique_itemsets)),\n\u001b[0;32m      6\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlist\u001b[39m(unique_itemsets) \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(unique_items),\n\u001b[0;32m      7\u001b[0m      \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0\u001b[39m}\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m itemsetitem_rating \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([itemsetitem_rating, negative_samples], ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.03 GiB for an array with shape (943025828,) and data type int64"
     ]
    }
   ],
   "source": [
    "unique_items = itemsetitem_trn['item'].unique()\n",
    "unique_itemsets = itemsetitem_trn['itemset'].unique()\n",
    "\n",
    "negative_samples = pd.DataFrame(\n",
    "    {'item': unique_items.repeat(len(unique_itemsets)),\n",
    "     'itemset': list(unique_itemsets) * len(unique_items),\n",
    "     'rating': 0}\n",
    ")\n",
    "\n",
    "itemsetitem_rating = pd.concat([itemsetitem_rating, negative_samples], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.03 GiB for an array with shape (1, 943025828) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m itemset_item_melt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mmelt(itemset_item_rating)\n\u001b[0;32m      2\u001b[0m itemset_item_melt\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\melt.py:159\u001b[0m, in \u001b[0;36mmelt\u001b[1;34m(frame, id_vars, value_vars, var_name, value_name, col_level, ignore_index)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[39mfor\u001b[39;00m i, col \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(var_name):\n\u001b[0;32m    151\u001b[0m     \u001b[39m# asanyarray will keep the columns as an Index\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \n\u001b[0;32m    153\u001b[0m     \u001b[39m# error: Incompatible types in assignment (expression has type \"ndarray\", target\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[39m# has type \"Series\")\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     mdata[col] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m    156\u001b[0m         frame\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39m_get_level_values(i)\n\u001b[0;32m    157\u001b[0m     )\u001b[39m.\u001b[39mrepeat(N)\n\u001b[1;32m--> 159\u001b[0m result \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39;49m_constructor(mdata, columns\u001b[39m=\u001b[39;49mmcolumns)\n\u001b[0;32m    161\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_index:\n\u001b[0;32m    162\u001b[0m     result\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m tile_compat(frame\u001b[39m.\u001b[39mindex, K)\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    665\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:154\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    151\u001b[0m axes \u001b[39m=\u001b[39m [columns, index]\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 154\u001b[0m     \u001b[39mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    155\u001b[0m         arrays, axes, consolidate\u001b[39m=\u001b[39;49mconsolidate\n\u001b[0;32m    156\u001b[0m     )\n\u001b[0;32m    157\u001b[0m \u001b[39melif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    158\u001b[0m     \u001b[39mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2199\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate)\u001b[0m\n\u001b[0;32m   2182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2183\u001b[0m     arrays: \u001b[39mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2184\u001b[0m     axes: \u001b[39mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2195\u001b[0m     \u001b[39m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[39m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2199\u001b[0m         blocks \u001b[39m=\u001b[39m _form_blocks(arrays, consolidate)\n\u001b[0;32m   2200\u001b[0m         mgr \u001b[39m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   2201\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2273\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate)\u001b[0m\n\u001b[0;32m   2270\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtype\u001b[39m.\u001b[39mtype, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m)):\n\u001b[0;32m   2271\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39mobject\u001b[39m)\n\u001b[1;32m-> 2273\u001b[0m values, placement \u001b[39m=\u001b[39m _stack_arrays(\u001b[39mlist\u001b[39;49m(tup_block), dtype)\n\u001b[0;32m   2274\u001b[0m \u001b[39mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2275\u001b[0m     values \u001b[39m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:2312\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2309\u001b[0m first \u001b[39m=\u001b[39m arrays[\u001b[39m0\u001b[39m]\n\u001b[0;32m   2310\u001b[0m shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(arrays),) \u001b[39m+\u001b[39m first\u001b[39m.\u001b[39mshape\n\u001b[1;32m-> 2312\u001b[0m stacked \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(shape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   2313\u001b[0m \u001b[39mfor\u001b[39;00m i, arr \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(arrays):\n\u001b[0;32m   2314\u001b[0m     stacked[i] \u001b[39m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.03 GiB for an array with shape (1, 943025828) and data type int64"
     ]
    }
   ],
   "source": [
    "itemset_item_melt = pd.melt(itemset_item_rating)\n",
    "itemset_item_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_df(df):\n",
    "\n",
    "    num_items = df.item.unique().shape[0]\n",
    "    num_itemsets = df.itemset.unique().shape[0]\n",
    "    \n",
    "    return df, num_items, num_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 42563, number of itemsets: 22156\n",
      "matrix sparsity: 0.999909\n",
      "   itemset   item\n",
      "0     8571  18506\n",
      "1     8571  33644\n",
      "2     8571  32627\n",
      "3     5725  14855\n",
      "4     5725  28037\n"
     ]
    }
   ],
   "source": [
    "data, num_items, num_itemsets = preprocessing_df(itemsetitem_trn)\n",
    "sparsity = 1 - len(data) / (num_items * num_itemsets)\n",
    "print(f'number of items: {num_items}, number of itemsets: {num_itemsets}')\n",
    "print(f'matrix sparsity: {sparsity:f}')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.42 GiB for an array with shape (26549, 42563) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inter_mat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((\u001b[39mlen\u001b[39;49m(itemsetitem_rating[\u001b[39m'\u001b[39;49m\u001b[39mitemset\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique()), \u001b[39mlen\u001b[39;49m(itemsetitem_rating[\u001b[39m'\u001b[39;49m\u001b[39mitem\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique())))\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m itemset, item, rating \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mitemset\u001b[39m\u001b[39m'\u001b[39m], itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m], itemsetitem_rating[\u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m]):\n\u001b[0;32m      3\u001b[0m     inter_mat[itemset][item] \u001b[39m=\u001b[39m rating\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.42 GiB for an array with shape (26549, 42563) and data type float64"
     ]
    }
   ],
   "source": [
    "inter_mat = np.zeros((len(itemsetitem_rating['itemset'].unique()), len(itemsetitem_rating['item'].unique())))\n",
    "for itemset, item, rating in zip(itemsetitem_rating['itemset'], itemsetitem_rating['item'], itemsetitem_rating['rating']):\n",
    "    inter_mat[itemset][item] = rating\n",
    "\n",
    "inter_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, mode='train'):\n",
    "        self.df = df\n",
    "        self.mode = mode\n",
    "        self.train_size = 0.8\n",
    "        self.val_size = 0.2\n",
    "\n",
    "        self.num_items = len(self.df['item'].unique())\n",
    "        self.num_itemset = len(self.df['itemset'].unique())\n",
    "\n",
    "        n_val = int(self.num_itemset * self.val_size)\n",
    "\n",
    "        np.random.seed(42)\n",
    "\n",
    "        val_indices = set(np.random.choice(range(self.num_itemset), n_val, replace = False))\n",
    "        train_indices = set(range(self.num_itemset)) - val_indices \n",
    "\n",
    "        if self.mode == 'train':\n",
    "            self.df = self.df[self.df['itemset'].isin(train_indices)]\n",
    "        elif self.mode == 'val':\n",
    "            self.df = self.df[self.df['itemset'].isin(val_indices)]\n",
    "\n",
    "        self.item = torch.tensor(self.df['item'].values)\n",
    "        self.itemset = torch.tensor(self.df['itemset'].values)\n",
    "        self.ratings = torch.tensor(self.df['rating'].values)\n",
    "        self.inter_mat = self.make_inter_mat()\n",
    "\n",
    "    def make_inter_mat(self):\n",
    "        inter_mat = self.df.pivot_table('rating', index='itemset', columns='item')\n",
    "        inter_mat.fillna(0, inplace = True)\n",
    "        inter_mat = inter_mat.values\n",
    "        return inter_mat\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.inter_mat)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # inter_mat = torch.tensor(self.inter_mat[self.users[index]]).float()\n",
    "        inter_mat = torch.tensor(self.inter_mat[index]).float()\n",
    "\n",
    "        return index, inter_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec(nn.Module):\n",
    "    def __init__(self, num_hidden, num_items, dropout=0.2):\n",
    "        super(AutoRec, self).__init__()\n",
    "        self.encoder = nn.Linear(num_items, num_hidden)\n",
    "        self.activate = nn.Sigmoid()\n",
    "        self.decoder = nn.Linear(num_hidden, num_items)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, mat):\n",
    "        hidden = self.dropout(self.activate(self.encoder(mat)))\n",
    "        pred = self.activate(self.decoder(hidden))\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_iter, criterion, optm, device):\n",
    "    model.train() # to train mode\n",
    "    loss_sum = 0\n",
    "    loss_cal_count = 0\n",
    "\n",
    "    for _, inter_mat in train_iter:\n",
    "        inter_mat = inter_mat.to(device)    \n",
    "\n",
    "        preds = model(inter_mat)\n",
    "        loss = criterion(preds, inter_mat)\n",
    "\n",
    "        # Update\n",
    "        optm.zero_grad()      # reset gradient \n",
    "        loss.backward()      # backpropagate\n",
    "        optm.step()      # optimizer update\n",
    "        \n",
    "        if not np.isnan(loss.cpu().detach().numpy()):\n",
    "            loss_cal_count += 1\n",
    "            loss_sum += loss.item()\n",
    "            \n",
    "    loss_avg = loss_sum / loss_cal_count\n",
    "\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, valid_iter, criterion, device):\n",
    "    \n",
    "    # np.random.seed(42)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        loss_sum = 0\n",
    "        loss_cal_count = 0\n",
    "        \n",
    "        for _, inter_mat in valid_iter:\n",
    "            inter_mat = inter_mat.to(device)\n",
    "            \n",
    "            # mask된 input으로 prediction 후 기존 정답 활용 loss값 계산\n",
    "            preds = model(inter_mat)\n",
    "            loss = criterion(preds, inter_mat)\n",
    "            \n",
    "            if not np.isnan(loss.cpu().numpy()):\n",
    "                loss_cal_count += 1\n",
    "                loss_sum += loss.item()\n",
    "      \n",
    "    loss_avg = loss_sum / loss_cal_count\n",
    "\n",
    "    return loss_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRec_loss_fn(nn.Module):\n",
    "\n",
    "    def __init__(self, loss_fn):\n",
    "        super(AutoRec_loss_fn, self).__init__()\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    def forward(self, pred, y):\n",
    "        y_for_compute = y.clone().to('cpu')\n",
    "        index = np.where(y_for_compute > 0) # FILL HERE : USE np.where & y_for_compute. WARNING: y를 사용 시, y의 device가 gpu일 경우 오류 발생 #\n",
    "        loss = self.loss_fn(pred[index], y[index])\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 50\n",
    "lr = 0.001\n",
    "batch_size = 16\n",
    "\n",
    "PATH = r'C:\\Users\\a3179\\OneDrive\\바탕 화면\\datamining_termproject/model/autorec.pt'\n",
    "patience = 5\n",
    "\n",
    "num_items = len(itemsetitem_rating['item'].unique())\n",
    "num_hidden = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df=itemsetitem_rating, mode='train')\n",
    "val_dataset = Dataset(df=itemsetitem_rating, mode='val')\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True) \n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoRec(num_hidden, num_items).to(device)\n",
    "loss = nn.BCELoss().to(device)\n",
    "optm = optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"주어진 patience 이후로 validation loss가 개선되지 않으면 학습을 조기 중지\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): validation loss가 개선된 후 기다리는 기간\n",
    "                            Default: 7\n",
    "            verbose (bool): True일 경우 각 validation loss의 개선 사항 메세지 출력\n",
    "                            Default: False\n",
    "            delta (float): 개선되었다고 인정되는 monitered quantity의 최소 변화\n",
    "                            Default: 0\n",
    "            path (str): checkpoint저장 경로\n",
    "                            Default: 'checkpoint.pt'\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''validation loss가 감소하면 모델을 저장한다.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (16x30849 and 42563x40)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(patience \u001b[39m=\u001b[39m patience, verbose \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, path\u001b[39m=\u001b[39mPATH)\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(num_epochs)):\n\u001b[1;32m----> 8\u001b[0m     train_loss \u001b[39m=\u001b[39m train(model, train_dataloader, loss, optm, device)\n\u001b[0;32m      9\u001b[0m     val_loss \u001b[39m=\u001b[39m validation(model, val_dataloader, loss, device)\n\u001b[0;32m     11\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[8], line 9\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_iter, criterion, optm, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m _, inter_mat \u001b[39min\u001b[39;00m train_iter:\n\u001b[0;32m      7\u001b[0m     inter_mat \u001b[39m=\u001b[39m inter_mat\u001b[39m.\u001b[39mto(device)    \n\u001b[1;32m----> 9\u001b[0m     preds \u001b[39m=\u001b[39m model(inter_mat)\n\u001b[0;32m     10\u001b[0m     loss \u001b[39m=\u001b[39m criterion(preds, inter_mat)\n\u001b[0;32m     12\u001b[0m     \u001b[39m# Update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mAutoRec.forward\u001b[1;34m(self, mat)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, mat):\n\u001b[1;32m---> 10\u001b[0m     hidden \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(mat)))\n\u001b[0;32m     11\u001b[0m     pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(hidden))\n\u001b[0;32m     13\u001b[0m     \u001b[39mreturn\u001b[39;00m pred\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\a3179\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16x30849 and 42563x40)"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience = patience, verbose = True, path=PATH)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "\n",
    "    train_loss = train(model, train_dataloader, loss, optm, device)\n",
    "    val_loss = validation(model, val_dataloader, loss, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    early_stopping(val_loss, model)\n",
    "\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "        \n",
    "    print(f'epoch: {epoch}, train Loss: {train_loss:.4f}, test Loss: {val_loss:.4f}')\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(train_losses,label=\"train_loss\")\n",
    "plt.plot(val_losses,label=\"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
